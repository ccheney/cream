# Agent Evaluations - Python Package
# See: docs/plans/14-testing.md lines 288-296
#
# This package contains:
# - DeepEval integration for LLM-as-Judge evaluations
# - G-Eval metric configuration
# - TaskCompletionMetric for agent scoring
#
# Install: uv pip install -e ".[dev]"
# Run: pytest tests/

[project]
name = "cream-evals"
version = "0.1.0"
description = "Agent evaluation framework for Cream trading system"
readme = "README.md"
license = { text = "AGPL-3.0-only" }
authors = [{ name = "Chris Cheney", email = "chris@cheney.dev" }]
requires-python = ">=3.14"

dependencies = [
    "deepeval>=3.7",
    "openai>=2.14",
    "google-generativeai>=0.8.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=9.0",
    "pytest-asyncio>=1.1",
    "mypy>=1.19",
    "ruff>=0.14",
]

# ============================================
# pytest Configuration
# ============================================
[tool.pytest.ini_options]
minversion = "8.0"
testpaths = ["tests"]
pythonpath = ["."]
asyncio_mode = "auto"
addopts = "-v"

markers = [
    "llm: marks tests that require LLM API calls",
    "slow: marks tests as slow",
]

# ============================================
# DeepEval Configuration
# ============================================
# Note: DeepEval configuration is in deepeval.yaml

# ============================================
# Ruff Configuration
# ============================================
[tool.ruff]
target-version = "py313"
line-length = 100

[tool.ruff.lint]
select = ["E", "W", "F", "I", "B", "C4", "UP"]

[tool.ruff.lint.per-file-ignores]
# Allow long lines in test data files (JSON expected outputs)
"cream_evals/datasets.py" = ["E501"]

# ============================================
# MyPy Configuration
# ============================================
[tool.mypy]
python_version = "3.13"
strict = true
